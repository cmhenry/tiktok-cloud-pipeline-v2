---
# GPU Worker Model Sync
# Syncs ML models from orchestrator to GPU worker local storage

- name: Ensure model directories exist
  file:
    path: "{{ item }}"
    state: directory
    owner: "{{ app_user }}"
    group: "{{ app_group }}"
    mode: '0755'
  loop:
    - "{{ gemma_model_path }}"
    - "{{ cope_adapter_path }}"
  tags: [models]

- name: Sync Gemma-2-9B model
  synchronize:
    src: "{{ model_source_path }}/gemma-2-9b/"
    dest: "{{ gemma_model_path }}/"
    mode: pull
    recursive: yes
    delete: yes
    rsync_opts:
      - "--info=progress2"
  delegate_to: "{{ inventory_hostname }}"
  tags: [models, gemma]

- name: Sync CoPE-A adapter
  synchronize:
    src: "{{ model_source_path }}/cope-a-adapter/"
    dest: "{{ cope_adapter_path }}/"
    mode: pull
    recursive: yes
    delete: yes
    rsync_opts:
      - "--info=progress2"
  delegate_to: "{{ inventory_hostname }}"
  tags: [models, cope]

- name: Check model directory sizes
  command: du -sh {{ item }}
  loop:
    - "{{ gemma_model_path }}"
    - "{{ cope_adapter_path }}"
  register: model_sizes
  changed_when: false
  tags: [models]

- name: Display model sizes
  debug:
    msg: "{{ model_sizes.results | map(attribute='stdout') | list }}"
  tags: [models]

- name: Verify Gemma model files exist
  find:
    paths: "{{ gemma_model_path }}"
    patterns: "*.safetensors"
    follow: yes
  register: gemma_check
  failed_when: gemma_check.files | length == 0
  tags: [models, verify]
